{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - 10/17/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "These functions are the same as lab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      " [['5.1', '3.5', '1.4', '0.2', 'Iris-setosa'], ['4.9', '3.0', '1.4', '0.2', 'Iris-setosa'], ['4.7', '3.2', '1.3', '0.2', 'Iris-setosa'], ['4.6', '3.1', '1.5', '0.2', 'Iris-setosa'], ['5.0', '3.6', '1.4', '0.2', 'Iris-setosa'], ['5.4', '3.9', '1.7', '0.4', 'Iris-setosa'], ['4.6', '3.4', '1.4', '0.3', 'Iris-setosa'], ['5.0', '3.4', '1.5', '0.2', 'Iris-setosa'], ['4.4', '2.9', '1.4', '0.2', 'Iris-setosa'], ['4.9', '3.1', '1.5', '0.1', 'Iris-setosa'], ['5.4', '3.7', '1.5', '0.2', 'Iris-setosa'], ['4.8', '3.4', '1.6', '0.2', 'Iris-setosa'], ['4.8', '3.0', '1.4', '0.1', 'Iris-setosa'], ['4.3', '3.0', '1.1', '0.1', 'Iris-setosa'], ['5.8', '4.0', '1.2', '0.2', 'Iris-setosa'], ['5.7', '4.4', '1.5', '0.4', 'Iris-setosa'], ['5.4', '3.9', '1.3', '0.4', 'Iris-setosa'], ['5.1', '3.5', '1.4', '0.3', 'Iris-setosa'], ['5.7', '3.8', '1.7', '0.3', 'Iris-setosa'], ['5.1', '3.8', '1.5', '0.3', 'Iris-setosa'], ['5.4', '3.4', '1.7', '0.2', 'Iris-setosa'], ['5.1', '3.7', '1.5', '0.4', 'Iris-setosa'], ['4.6', '3.6', '1.0', '0.2', 'Iris-setosa'], ['5.1', '3.3', '1.7', '0.5', 'Iris-setosa'], ['4.8', '3.4', '1.9', '0.2', 'Iris-setosa'], ['5.0', '3.0', '1.6', '0.2', 'Iris-setosa'], ['5.0', '3.4', '1.6', '0.4', 'Iris-setosa'], ['5.2', '3.5', '1.5', '0.2', 'Iris-setosa'], ['5.2', '3.4', '1.4', '0.2', 'Iris-setosa'], ['4.7', '3.2', '1.6', '0.2', 'Iris-setosa'], ['4.8', '3.1', '1.6', '0.2', 'Iris-setosa'], ['5.4', '3.4', '1.5', '0.4', 'Iris-setosa'], ['5.2', '4.1', '1.5', '0.1', 'Iris-setosa'], ['5.5', '4.2', '1.4', '0.2', 'Iris-setosa'], ['4.9', '3.1', '1.5', '0.1', 'Iris-setosa'], ['5.0', '3.2', '1.2', '0.2', 'Iris-setosa'], ['5.5', '3.5', '1.3', '0.2', 'Iris-setosa'], ['4.9', '3.1', '1.5', '0.1', 'Iris-setosa'], ['4.4', '3.0', '1.3', '0.2', 'Iris-setosa'], ['5.1', '3.4', '1.5', '0.2', 'Iris-setosa'], ['7.0', '3.2', '4.7', '1.4', 'Iris-versicolor'], ['6.4', '3.2', '4.5', '1.5', 'Iris-versicolor'], ['6.9', '3.1', '4.9', '1.5', 'Iris-versicolor'], ['5.5', '2.3', '4.0', '1.3', 'Iris-versicolor'], ['6.5', '2.8', '4.6', '1.5', 'Iris-versicolor'], ['5.7', '2.8', '4.5', '1.3', 'Iris-versicolor'], ['6.3', '3.3', '4.7', '1.6', 'Iris-versicolor'], ['4.9', '2.4', '3.3', '1.0', 'Iris-versicolor'], ['6.6', '2.9', '4.6', '1.3', 'Iris-versicolor'], ['5.2', '2.7', '3.9', '1.4', 'Iris-versicolor'], ['5.0', '2.0', '3.5', '1.0', 'Iris-versicolor'], ['5.9', '3.0', '4.2', '1.5', 'Iris-versicolor'], ['6.0', '2.2', '4.0', '1.0', 'Iris-versicolor'], ['6.1', '2.9', '4.7', '1.4', 'Iris-versicolor'], ['5.6', '2.9', '3.6', '1.3', 'Iris-versicolor'], ['6.7', '3.1', '4.4', '1.4', 'Iris-versicolor'], ['5.6', '3.0', '4.5', '1.5', 'Iris-versicolor'], ['5.8', '2.7', '4.1', '1.0', 'Iris-versicolor'], ['6.2', '2.2', '4.5', '1.5', 'Iris-versicolor'], ['5.6', '2.5', '3.9', '1.1', 'Iris-versicolor'], ['5.9', '3.2', '4.8', '1.8', 'Iris-versicolor'], ['6.1', '2.8', '4.0', '1.3', 'Iris-versicolor'], ['6.3', '2.5', '4.9', '1.5', 'Iris-versicolor'], ['6.1', '2.8', '4.7', '1.2', 'Iris-versicolor'], ['6.4', '2.9', '4.3', '1.3', 'Iris-versicolor'], ['6.6', '3.0', '4.4', '1.4', 'Iris-versicolor'], ['6.8', '2.8', '4.8', '1.4', 'Iris-versicolor'], ['6.7', '3.0', '5.0', '1.7', 'Iris-versicolor'], ['6.0', '2.9', '4.5', '1.5', 'Iris-versicolor'], ['5.7', '2.6', '3.5', '1.0', 'Iris-versicolor'], ['5.5', '2.4', '3.8', '1.1', 'Iris-versicolor'], ['5.5', '2.4', '3.7', '1.0', 'Iris-versicolor'], ['5.8', '2.7', '3.9', '1.2', 'Iris-versicolor'], ['6.0', '2.7', '5.1', '1.6', 'Iris-versicolor'], ['5.4', '3.0', '4.5', '1.5', 'Iris-versicolor'], ['6.0', '3.4', '4.5', '1.6', 'Iris-versicolor'], ['6.7', '3.1', '4.7', '1.5', 'Iris-versicolor'], ['6.3', '2.3', '4.4', '1.3', 'Iris-versicolor'], ['5.6', '3.0', '4.1', '1.3', 'Iris-versicolor'], ['5.5', '2.5', '4.0', '1.3', 'Iris-versicolor'], ['6.3', '3.3', '6.0', '2.5', 'Iris-virginica'], ['5.8', '2.7', '5.1', '1.9', 'Iris-virginica'], ['7.1', '3.0', '5.9', '2.1', 'Iris-virginica'], ['6.3', '2.9', '5.6', '1.8', 'Iris-virginica'], ['6.5', '3.0', '5.8', '2.2', 'Iris-virginica'], ['7.6', '3.0', '6.6', '2.1', 'Iris-virginica'], ['4.9', '2.5', '4.5', '1.7', 'Iris-virginica'], ['7.3', '2.9', '6.3', '1.8', 'Iris-virginica'], ['6.7', '2.5', '5.8', '1.8', 'Iris-virginica'], ['7.2', '3.6', '6.1', '2.5', 'Iris-virginica'], ['6.5', '3.2', '5.1', '2.0', 'Iris-virginica'], ['6.4', '2.7', '5.3', '1.9', 'Iris-virginica'], ['6.8', '3.0', '5.5', '2.1', 'Iris-virginica'], ['5.7', '2.5', '5.0', '2.0', 'Iris-virginica'], ['5.8', '2.8', '5.1', '2.4', 'Iris-virginica'], ['6.4', '3.2', '5.3', '2.3', 'Iris-virginica'], ['6.5', '3.0', '5.5', '1.8', 'Iris-virginica'], ['7.7', '3.8', '6.7', '2.2', 'Iris-virginica'], ['7.7', '2.6', '6.9', '2.3', 'Iris-virginica'], ['6.0', '2.2', '5.0', '1.5', 'Iris-virginica'], ['6.9', '3.2', '5.7', '2.3', 'Iris-virginica'], ['5.6', '2.8', '4.9', '2.0', 'Iris-virginica'], ['7.7', '2.8', '6.7', '2.0', 'Iris-virginica'], ['6.3', '2.7', '4.9', '1.8', 'Iris-virginica'], ['6.7', '3.3', '5.7', '2.1', 'Iris-virginica'], ['7.2', '3.2', '6.0', '1.8', 'Iris-virginica'], ['6.2', '2.8', '4.8', '1.8', 'Iris-virginica'], ['6.1', '3.0', '4.9', '1.8', 'Iris-virginica'], ['6.4', '2.8', '5.6', '2.1', 'Iris-virginica'], ['7.2', '3.0', '5.8', '1.6', 'Iris-virginica'], ['7.4', '2.8', '6.1', '1.9', 'Iris-virginica'], ['7.9', '3.8', '6.4', '2.0', 'Iris-virginica'], ['6.4', '2.8', '5.6', '2.2', 'Iris-virginica'], ['6.3', '2.8', '5.1', '1.5', 'Iris-virginica'], ['6.1', '2.6', '5.6', '1.4', 'Iris-virginica'], ['7.7', '3.0', '6.1', '2.3', 'Iris-virginica'], ['6.3', '3.4', '5.6', '2.4', 'Iris-virginica'], ['6.4', '3.1', '5.5', '1.8', 'Iris-virginica'], ['6.0', '3.0', '4.8', '1.8', 'Iris-virginica'], ['6.9', '3.1', '5.4', '2.1', 'Iris-virginica']]\n",
      "Test set:\n",
      " [['5.0', '3.5', '1.3', '0.3', 'Iris-setosa'], ['4.5', '2.3', '1.3', '0.3', 'Iris-setosa'], ['4.4', '3.2', '1.3', '0.2', 'Iris-setosa'], ['5.0', '3.5', '1.6', '0.6', 'Iris-setosa'], ['5.1', '3.8', '1.9', '0.4', 'Iris-setosa'], ['4.8', '3.0', '1.4', '0.3', 'Iris-setosa'], ['5.1', '3.8', '1.6', '0.2', 'Iris-setosa'], ['4.6', '3.2', '1.4', '0.2', 'Iris-setosa'], ['5.3', '3.7', '1.5', '0.2', 'Iris-setosa'], ['5.0', '3.3', '1.4', '0.2', 'Iris-setosa'], ['5.5', '2.6', '4.4', '1.2', 'Iris-versicolor'], ['6.1', '3.0', '4.6', '1.4', 'Iris-versicolor'], ['5.8', '2.6', '4.0', '1.2', 'Iris-versicolor'], ['5.0', '2.3', '3.3', '1.0', 'Iris-versicolor'], ['5.6', '2.7', '4.2', '1.3', 'Iris-versicolor'], ['5.7', '3.0', '4.2', '1.2', 'Iris-versicolor'], ['5.7', '2.9', '4.2', '1.3', 'Iris-versicolor'], ['6.2', '2.9', '4.3', '1.3', 'Iris-versicolor'], ['5.1', '2.5', '3.0', '1.1', 'Iris-versicolor'], ['5.7', '2.8', '4.1', '1.3', 'Iris-versicolor'], ['6.7', '3.1', '5.6', '2.4', 'Iris-virginica'], ['6.9', '3.1', '5.1', '2.3', 'Iris-virginica'], ['5.8', '2.7', '5.1', '1.9', 'Iris-virginica'], ['6.8', '3.2', '5.9', '2.3', 'Iris-virginica'], ['6.7', '3.3', '5.7', '2.5', 'Iris-virginica'], ['6.7', '3.0', '5.2', '2.3', 'Iris-virginica'], ['6.3', '2.5', '5.0', '1.9', 'Iris-virginica'], ['6.5', '3.0', '5.2', '2.0', 'Iris-virginica'], ['6.2', '3.4', '5.4', '2.3', 'Iris-virginica'], ['5.9', '3.0', '5.1', '1.8', 'Iris-virginica']]\n",
      "x_test (features):\n",
      " [[5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "y_test (enumerated labels):\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Name: Yi Qian Goh\n",
    "Date: 10/17/2024\n",
    "Class: CSEN140 Machine Learning and Data Mining\n",
    "Brief Description: This program implements Linear Discriminant Analysis (LDA) and Quadratic Discriminant Analysis (QDA) \n",
    "                using only NumPy. It does not use any machine learning library (e.g. Scikit-learn). Classifications are performed on the \n",
    "                same Iris dataset as Lab 3.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#Function to transform text file of data instances into a List[List[]]\n",
    "def txt_to_list(filename):\n",
    "    dtype = [('col1', np.float64), ('col2', np.float64), ('col3', np.float64), ('col4', np.float64), ('col5', 'U20')]\n",
    "    data = np.genfromtxt(filename, dtype=dtype, delimiter=',')\n",
    "    data_list = []\n",
    "    for row in data:\n",
    "        data_list.append([np.float64(row[0]), np.float64(row[1]), np.float64(row[2]), np.float64(row[3]), str(row[4])])\n",
    "    return data_list\n",
    "\n",
    "#Function to check if dataset is in proper form\n",
    "def test_dataset(data):\n",
    "    if len(data) != 150:\n",
    "        print('list length incorrect')\n",
    "        return False\n",
    "    for row in data:\n",
    "        if len(row) != 5:\n",
    "            print('row does not have exactly 5 elements')\n",
    "            return False\n",
    "        for column in row[:-1]:\n",
    "            if type(column) != np.float64:\n",
    "                print('column type, excluding last one, is not np.float64')\n",
    "                return False\n",
    "        if type(row[-1]) != str:\n",
    "            print('last element of row is not string')\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "#Function to split data into training and test sets\n",
    "def split_data(data_list):\n",
    "    data_arr = np.array(data_list)\n",
    "    category, count = np.unique(data_arr[:, -1], return_counts=True)\n",
    "    all_freq = dict(zip(category, count))\n",
    "    training_set = []  # 80%\n",
    "    test_set = []  # 20%\n",
    "    for cat in category:\n",
    "        count_of_category = all_freq.get(cat)\n",
    "        category_data = data_arr[data_arr[:, -1] == cat]\n",
    "        num_training = int(count_of_category * 0.8)\n",
    "        training_set.extend(category_data[:num_training].tolist())\n",
    "        test_set.extend(category_data[num_training:].tolist())\n",
    "    return training_set, test_set\n",
    "\n",
    "#Load the dataset from the text file\n",
    "data_list = txt_to_list('iris.data.txt')\n",
    "\n",
    "#Split the data into training and test sets\n",
    "training_set, test_set = split_data(data_list)\n",
    "\n",
    "print(\"Training set:\\n\", training_set)\n",
    "print(\"Test set:\\n\", test_set)\n",
    "\n",
    "\n",
    "#Separate features and labels for training and test sets\n",
    "x_train = np.array([row[:-1] for row in training_set]).astype(np.float64)\n",
    "y_train = np.array([row[-1] for row in training_set])\n",
    "x_test = np.array([row[:-1] for row in test_set]).astype(np.float64)\n",
    "y_test = np.array([row[-1] for row in test_set])\n",
    "#Encode labels to numerical values\n",
    "label_encoder = {label: idx for idx, label in enumerate(np.unique(y_train))}\n",
    "y_train = np.array([label_encoder[label] for label in y_train])\n",
    "y_test = np.array([label_encoder[label] for label in y_test])\n",
    "\n",
    "print(\"x_test (features):\\n\", x_test)\n",
    "print(\"y_test (enumerated labels):\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function used to see what percentage of the predicted outcome matches to the true classification\n",
    "def get_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Class and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA training accuracy: 97.5 %\n",
      "LDA test accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "#Linear Discriminant Analysis\n",
    "class LDA:\n",
    "    def train(self, x, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_features = x.shape[1]\n",
    "        self.means = {}\n",
    "        self.covariance = np.zeros((n_features, n_features))\n",
    "        for c in self.classes:\n",
    "            x_c = x[y == c]\n",
    "            self.means[c] = np.mean(x_c, axis=0)\n",
    "            self.covariance += np.cov(x_c, rowvar=False)\n",
    "\n",
    "    def predict(self, x):\n",
    "        #covariances are the same in the probabilty of each class\n",
    "        inv_cov = np.linalg.inv(self.covariance)\n",
    "        predictions = []\n",
    "        for x in x:\n",
    "            class_scores = []\n",
    "            for c in self.classes:\n",
    "                mean_vec = self.means[c]\n",
    "                class_scores.append(\n",
    "                    np.exp(-0.5 * np.dot(np.dot((x - mean_vec).T, inv_cov), (x - mean_vec)))\n",
    "                )\n",
    "            predictions.append(self.classes[np.argmax(class_scores)])\n",
    "        return np.array(predictions)\n",
    "    \n",
    "#Train and test LDA\n",
    "lda = LDA()\n",
    "lda.train(x_train, y_train)\n",
    "y_train_pred = lda.predict(x_train)\n",
    "y_test_pred = lda.predict(x_test)\n",
    "print(\"LDA training accuracy:\", get_accuracy(y_train, y_train_pred), \"%\")\n",
    "print(\"LDA test accuracy:\", get_accuracy(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA Class and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QDA training accuracy: 98.33333333333333 %\n",
      "QDA test accuracy: 100.0 %\n",
      "QDA duration: 0.002796649932861328 seconds\n",
      "Classes:\n",
      " [0 1 2]\n",
      "Covariances:\n",
      " {0: array([[0.13112179, 0.09897436, 0.01298077, 0.01362179],\n",
      "       [0.09897436, 0.13271795, 0.00205128, 0.0145641 ],\n",
      "       [0.01298077, 0.00205128, 0.02958333, 0.00458333],\n",
      "       [0.01362179, 0.0145641 , 0.00458333, 0.00994231]]), 1: array([[0.27374359, 0.08661538, 0.17212821, 0.05230769],\n",
      "       [0.08661538, 0.11087179, 0.08087179, 0.04538462],\n",
      "       [0.17212821, 0.08087179, 0.20353205, 0.07371795],\n",
      "       [0.05230769, 0.04538462, 0.07371795, 0.04307692]]), 2: array([[0.46794231, 0.11041026, 0.35777564, 0.05125641],\n",
      "       [0.11041026, 0.11323077, 0.08107692, 0.04625641],\n",
      "       [0.35777564, 0.08107692, 0.34532692, 0.05930769],\n",
      "       [0.05125641, 0.04625641, 0.05930769, 0.07425641]])}\n",
      "Means:\n",
      " {0: array([5.0375, 3.44  , 1.4625, 0.2325]), 1: array([6.01  , 2.78  , 4.3175, 1.35  ]), 2: array([6.6225, 2.96  , 5.6075, 1.99  ])}\n"
     ]
    }
   ],
   "source": [
    "#Quadratic Discriminant Analysis\n",
    "class QDA:\n",
    "    def train(self, x, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.means = {}\n",
    "        self.covariances = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            x_c = x[y == c]\n",
    "            self.means[c] = np.mean(x_c, axis=0)\n",
    "            self.covariances[c] = np.cov(x_c, rowvar=False)\n",
    "\n",
    "    def predict(self, x):\n",
    "        predictions = []\n",
    "        for x in x:\n",
    "            class_scores = []\n",
    "            for c in self.classes:\n",
    "                mean_vec = self.means[c]\n",
    "                cov_matrix = self.covariances[c]\n",
    "                inv_cov = np.linalg.inv(cov_matrix)\n",
    "                ratio = 1/(np.power(2*np.pi, 2) * np.power(np.linalg.det(cov_matrix), 0.5))\n",
    "                exponential = np.exp(-0.5 * np.dot(np.dot((x - mean_vec).T, inv_cov), (x - mean_vec))) \n",
    "                class_scores.append(ratio * exponential)\n",
    "            predictions.append(self.classes[np.argmax(class_scores)])\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "#Train and test QDA\n",
    "start_time = time.time()\n",
    "qda = QDA()\n",
    "qda.train(x_train, y_train)\n",
    "qda_train_time = time.time() - start_time\n",
    "y_train_pred = qda.predict(x_train)\n",
    "y_test_pred = qda.predict(x_test)\n",
    "print(\"\\nQDA training accuracy:\", get_accuracy(y_train, y_train_pred), \"%\")\n",
    "print(\"QDA test accuracy:\", get_accuracy(y_test, y_test_pred), \"%\")\n",
    "print(\"QDA duration:\", qda_train_time, \"seconds\")\n",
    "\n",
    "#check QDA classes, means and covariances\n",
    "qda = QDA()\n",
    "qda.train(x_train, y_train)\n",
    "print(\"Classes:\\n\", qda.classes)\n",
    "print(\"Covariances:\\n\", qda.covariances)\n",
    "print(\"Means:\\n\", qda.means)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonal QDA Class and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagonal QDA Training Accuracy: 95.83333333333334 %\n",
      "Diagonal QDA Test Accuracy: 100.0 %\n",
      "Diagonal QDA Duration: 0.0015060901641845703 seconds\n"
     ]
    }
   ],
   "source": [
    "#QDA with Diagonal Covariance Matrix\n",
    "class diagonal_qda:\n",
    "    def train(self, x, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.means = {}\n",
    "        self.covariances = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            x_c = x[y == c]\n",
    "            self.means[c] = np.mean(x_c, axis=0)\n",
    "            self.covariances[c] = np.diag(np.var(x_c, axis=0))\n",
    "\n",
    "    def predict(self, x):\n",
    "        predictions = []\n",
    "        for x in x:\n",
    "            class_scores = []\n",
    "            for c in self.classes:\n",
    "                mean_vec = self.means[c]\n",
    "                cov_matrix = self.covariances[c]\n",
    "                inv_cov = np.linalg.inv(cov_matrix)\n",
    "                ratio = 1/(np.power(2*np.pi, 2) * np.power(np.linalg.det(cov_matrix), 0.5))\n",
    "                exponential = np.exp(-0.5 * np.dot(np.dot((x - mean_vec).T, inv_cov), (x - mean_vec))) \n",
    "                class_scores.append(ratio * exponential)\n",
    "            predictions.append(self.classes[np.argmax(class_scores)])\n",
    "        return np.array(predictions)\n",
    "\n",
    "#Train and test Diagonal QDA\n",
    "start_time = time.time()\n",
    "diag_qda = diagonal_qda()\n",
    "diag_qda.train(x_train, y_train)\n",
    "diag_qda_train_time = time.time() - start_time\n",
    "y_train_pred_diag = diag_qda.predict(x_train)\n",
    "y_test_pred_diag = diag_qda.predict(x_test)\n",
    "print(\"\\nDiagonal QDA Training Accuracy:\", get_accuracy(y_train, y_train_pred_diag), \"%\")\n",
    "print(\"Diagonal QDA Test Accuracy:\", get_accuracy(y_test, y_test_pred_diag), \"%\")\n",
    "print(\"Diagonal QDA Duration:\", diag_qda_train_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setosa LDA training accuracy:  100.0 %\n",
      "Setosa LDA test accuracy:  100.0 %\n",
      "Setosa QDA training accuracy:  100.0 %\n",
      "Setosa QDA test accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "#Trains, tests, and returns accuracy of training and testing using both LDA and QDA.\n",
    "def binary_classification(irisTypeString, x_train, y_train, x_test, y_test):\n",
    "    #enumerate label np.arrays into 1s and 0s. Those that match the irisTypeString becomes 1 and others are 0.\n",
    "    #Thus, transforming 3 classes into 2 classes. \n",
    "    y_train_bin = np.where(y_train == label_encoder[irisTypeString], 1, 0)\n",
    "    y_train_true =  np.where(y_train == label_encoder[irisTypeString], 1, 0)\n",
    "    y_test_true = np.where(y_test == label_encoder[irisTypeString], 1, 0)\n",
    "\n",
    "    #create LDA class object and perform training and prediction. Then get accuracy of both the training set and the text set predictions.\n",
    "    lda = LDA()\n",
    "    lda.train(x_train, y_train_bin)\n",
    "    y_train_pred = lda.predict(x_train)\n",
    "    y_test_pred = lda.predict(x_test)\n",
    "    lda_training_acc = get_accuracy(y_train_true, y_train_pred)\n",
    "    lda_test_acc = get_accuracy(y_test_true, y_test_pred)\n",
    "\n",
    "    #same as LDA, but with QDA\n",
    "    qda = QDA()\n",
    "    qda.train(x_train, y_train_bin)\n",
    "    y_train_pred = qda.predict(x_train)\n",
    "    y_test_pred = qda.predict(x_test)\n",
    "    qda_training_acc = get_accuracy(y_train_true, y_train_pred)\n",
    "    qda_test_acc = get_accuracy(y_test_true, y_test_pred)\n",
    "\n",
    "    return lda_training_acc, lda_test_acc, qda_training_acc, qda_test_acc\n",
    "\n",
    "\n",
    "lda_train_acc, lda_test_acc, qda_train_acc, qda_test_acc = binary_classification('Iris-setosa', x_train, y_train, x_test, y_test)\n",
    "print(\"Setosa LDA training accuracy: \", lda_train_acc, \"%\")\n",
    "print(\"Setosa LDA test accuracy: \", lda_test_acc, \"%\")\n",
    "print(\"Setosa QDA training accuracy: \", qda_train_acc, \"%\")\n",
    "print(\"Setosa QDA test accuracy: \", qda_test_acc, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------Overall Accuracy----------------------------------------\n",
      "LDA training accuracy: 97.5 %\n",
      "LDA test accuracy: 100.0\n",
      "\n",
      "QDA training accuracy: 98.33333333333333 %\n",
      "QDA test accuracy: 100.0 %\n",
      "QDA duration: 0.0 seconds\n",
      "\n",
      "Diagonal QDA Training Accuracy: 95.83333333333334 %\n",
      "Diagonal QDA Test Accuracy: 100.0 %\n",
      "Diagonal QDA Duration: 0.0 seconds\n",
      "\n",
      "\n",
      "---------------------------Binary Classification and Accuracy---------------------------------\n",
      "\n",
      "\n",
      "Accuracy on Setosa Data\n",
      "-------------------------------------------------\n",
      "Setosa LDA training accuracy:  100.0 %\n",
      "Setosa LDA test accuracy:  100.0 %\n",
      "Setosa QDA training accuracy:  100.0 %\n",
      "Setosa QDA test accuracy:  100.0 %\n",
      "\n",
      "\n",
      "Accuracy on Versicolor Data\n",
      "-------------------------------------------------\n",
      "Versicolor LDA training accuracy:  70.83333333333334 %\n",
      "Versicolor LDA test accuracy:  90.0 %\n",
      "Versicolor QDA training accuracy:  97.5 %\n",
      "Versicolor QDA test accuracy:  96.66666666666667 %\n",
      "\n",
      "\n",
      "Accuracy on Virginica Data\n",
      "-------------------------------------------------\n",
      "Virginica LDA training accuracy:  86.66666666666667 %\n",
      "Virginica LDA test accuracy:  96.66666666666667 %\n",
      "Virginica QDA training accuracy:  96.66666666666667 %\n",
      "Virginica QDA test accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------Overall Accuracy----------------------------------------\")\n",
    "\n",
    "#Train and test LDA\n",
    "lda = LDA()\n",
    "lda.train(x_train, y_train)\n",
    "y_train_pred = lda.predict(x_train)\n",
    "y_test_pred = lda.predict(x_test)\n",
    "print(\"LDA training accuracy:\", get_accuracy(y_train, y_train_pred), \"%\")\n",
    "print(\"LDA test accuracy:\", get_accuracy(y_test, y_test_pred))\n",
    "\n",
    "#Train and test QDA\n",
    "start_time = time.time()\n",
    "qda = QDA()\n",
    "qda.train(x_train, y_train)\n",
    "qda_train_time = time.time() - start_time\n",
    "y_train_pred = qda.predict(x_train)\n",
    "y_test_pred = qda.predict(x_test)\n",
    "print(\"\\nQDA training accuracy:\", get_accuracy(y_train, y_train_pred), \"%\")\n",
    "print(\"QDA test accuracy:\", get_accuracy(y_test, y_test_pred), \"%\")\n",
    "print(\"QDA duration:\", qda_train_time, \"seconds\")\n",
    "\n",
    "#Train and test Diagonal QDA\n",
    "start_time = time.time()\n",
    "diag_qda = diagonal_qda()\n",
    "diag_qda.train(x_train, y_train)\n",
    "diag_qda_train_time = time.time() - start_time\n",
    "y_train_pred_diag = diag_qda.predict(x_train)\n",
    "y_test_pred_diag = diag_qda.predict(x_test)\n",
    "print(\"\\nDiagonal QDA Training Accuracy:\", get_accuracy(y_train, y_train_pred_diag), \"%\")\n",
    "print(\"Diagonal QDA Test Accuracy:\", get_accuracy(y_test, y_test_pred_diag), \"%\")\n",
    "print(\"Diagonal QDA Duration:\", diag_qda_train_time, \"seconds\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\n---------------------------Binary Classification and Accuracy---------------------------------\")\n",
    "print(\"\\n\\nAccuracy on Setosa Data\\n-------------------------------------------------\")\n",
    "#call binary_classification class to train and test each method and data set.\n",
    "lda_train_acc, lda_test_acc, qda_train_acc, qda_test_acc = binary_classification('Iris-setosa', x_train, y_train, x_test, y_test)\n",
    "print(\"Setosa LDA training accuracy: \", lda_train_acc, \"%\")\n",
    "print(\"Setosa LDA test accuracy: \", lda_test_acc, \"%\")\n",
    "print(\"Setosa QDA training accuracy: \", qda_train_acc, \"%\")\n",
    "print(\"Setosa QDA test accuracy: \", qda_test_acc, \"%\")\n",
    "\n",
    "print(\"\\n\\nAccuracy on Versicolor Data\\n-------------------------------------------------\")\n",
    "#call binary_classification class to train and test each method and data set.\n",
    "lda_train_acc, lda_test_acc, qda_train_acc, qda_test_acc = binary_classification('Iris-versicolor', x_train, y_train, x_test, y_test)\n",
    "print(\"Versicolor LDA training accuracy: \", lda_train_acc, \"%\")\n",
    "print(\"Versicolor LDA test accuracy: \", lda_test_acc, \"%\")\n",
    "print(\"Versicolor QDA training accuracy: \", qda_train_acc, \"%\")\n",
    "print(\"Versicolor QDA test accuracy: \", qda_test_acc, \"%\")\n",
    "\n",
    "print(\"\\n\\nAccuracy on Virginica Data\\n-------------------------------------------------\")\n",
    "#call binary_classification class to train and test each method and data set.\n",
    "lda_train_acc, lda_test_acc, qda_train_acc, qda_test_acc = binary_classification('Iris-virginica', x_train, y_train, x_test, y_test)\n",
    "print(\"Virginica LDA training accuracy: \", lda_train_acc, \"%\")\n",
    "print(\"Virginica LDA test accuracy: \", lda_test_acc, \"%\")\n",
    "print(\"Virginica QDA training accuracy: \", qda_train_acc, \"%\")\n",
    "print(\"Virginica QDA test accuracy: \", qda_test_acc, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Q1 Is there any class linearly separable from other classes? Explain your answer based on your experiments.\n",
    "We can infer whether any class is linearly separable from the others by evaluating the accuracy rates and misclassifications. The accuracy rate is 100% for both the testing and training datasets in LDA and QDA for the Setosa class. This means that the Setosa class is linearly separable from the other classes. It is perfectly classified in all cases without any errors, indicating that a linear decision boundary can separate this class from the others.\n",
    "\n",
    "Both Versicolor and Virginica have errors in classification. In the LDA results, Versicolor is often misclassified as Virginica and vice versa, as seen in the specific index errors during both training and testing. The LDA training accuracy are 69.17% and 88.33% for the Versicolor and Virginica classes respectively. This suggests that Versicolor and Virginica are not perfectly linearly separable. They are harder to distinguish from each other using LDA, which assumes shared covariance, but QDA (which accounts for different covariances) does a better job at separating them, albeit with some errors during training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
